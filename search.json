[
  {
    "objectID": "impl.html",
    "href": "impl.html",
    "title": "Implementation",
    "section": "",
    "text": "from typing import Tuple\nimport torch, torch.utils.data, torch.nn as nn, torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torchvision.datasets import ImageNet\nfrom torchvision.models import vgg16, VGG16_Weights, vgg11, VGG11_Weights, alexnet, AlexNet_Weights\nfrom lovely_tensors import monkey_patch\nfrom torchinfo import summary\n\n\nmonkey_patch()\n\n\nLoad some images\n\nin_stats = ( (0.485, 0.456, 0.406),     # mean \n             (0.229, 0.224, 0.225) )    # std\n\ntfms = T.Compose([\n            T.Resize((224, 224)),\n            T.ToTensor(),\n            T.Normalize(mean=in_stats[0], std=in_stats[1])\n    ])\n\ntrain = ImageNet(root=\"~/work/datasets/ImageNet\", split=\"train\", transform=tfms)\nval = ImageNet(root=\"~/work/datasets/ImageNet\", split=\"val\", transform=tfms)\n\n\nimage, label = train[0]\n\nprint(f\"Label: {label} Image: {image}\")\nimage.rgb(denorm=in_stats)\n\nLabel: 0 Image: tensor[3, 224, 224] n=150528 x∈[-2.101, 2.640] μ=0.125 σ=1.512\n\n\n\n\n\nConfirm it works. The image belongs to class 0 - tench (a fish species)\n\n(alexnet(weights=AlexNet_Weights.DEFAULT)\n    .requires_grad_(False)\n    .eval()(image[None])[0].argmax().item()\n)\n\n0\n\n\n\n\nLoad and hook into AlexNet\n\nLoad AlexNet (the one from the “This one weird trick” paper, not the OG one Z&F used)\nConvert ReLu and Dropout to not be in-place.\n\n\n# The feature extractor part of the model\nf: nn.Sequential = alexnet(weights=AlexNet_Weights.DEFAULT).features\nf.requires_grad_(False).eval()\n\nfor l in f:\n    # Disable inplace for ReLU and Dropout.\n    # Otherwise they overwrite the previous layers output.\n    if hasattr(l, \"inplace\"):\n        l.inplace = False\nf\n\nSequential(\n  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (4): ReLU()\n  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (7): ReLU()\n  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (9): ReLU()\n  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (11): ReLU()\n  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n)\n\n\n\n\nVisualizing the weights of the first Conv layer.\nScale so that most (+/- 3σ) RGB values are in [0..1], clip the rest.\n\nw1 = f[0].weight\nw1.plt\n\n\n\n\n\ndef sigmas(x: torch.Tensor, n=3):\n    x /= x.std()*n*2 # *2 because I want +/- n sigmas\n    return x - x.mean() + 0.5\n\n\nsigmas(w1).plt\n\n\n\n\n\nsigmas(w1).clip(0, 1).rgb(gutter_px=0, scale=5)\n\n\n\n\n\n\nExplore the activations\n\nHook into activations\n\nAttach a hook that saves every modules input and output\nRun 1 image through the model to save in/out values for every layer.\n\n\ndef save_hook(m: nn.Module, i: Tuple[torch.Tensor], o: torch.Tensor):\n    m.inp = i[0] # torch passses a tuple because that's how forward() works in general.\n    m.out = o\n\nfor l in f:\n    if not hasattr(l, \"hooked\"):\n        l.register_forward_hook(save_hook)\n        l.hooked=True\n\nf(image[None]) # Outputs 6x6x256 feature map, but we only care about the layer activations.\n\ntensor[1, 256, 6, 6] n=9216 x∈[0., 24.330] μ=0.619 σ=1.803\n\n\n\nLayer activations\n\n\nfor i, l in enumerate(f):\n    print(f\"{i}: {l}\")\n    if not i: print(f\"\\tIn:  {l.inp}\") # For other layers, input=previous layers output.\n    print(f\"\\tOut: {l.out}\")\n\n0: Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    In:  tensor[1, 3, 224, 224] n=150528 x∈[-2.101, 2.640] μ=0.125 σ=1.512\n    Out: tensor[1, 64, 55, 55] n=193600 x∈[-34.649, 32.174] μ=-0.398 σ=3.305\n1: ReLU()\n    Out: tensor[1, 64, 55, 55] n=193600 x∈[0., 32.174] μ=0.718 σ=1.886\n2: MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    Out: tensor[1, 64, 27, 27] n=46656 x∈[0., 32.174] μ=1.977 σ=2.887\n3: Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    Out: tensor[1, 192, 27, 27] n=139968 x∈[-168.725, 60.178] μ=-9.465 σ=13.468\n4: ReLU()\n    Out: tensor[1, 192, 27, 27] n=139968 x∈[0., 60.178] μ=0.836 σ=2.859\n5: MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    Out: tensor[1, 192, 13, 13] n=32448 x∈[0., 60.178] μ=2.660 σ=4.923\n6: Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    Out: tensor[1, 384, 13, 13] n=64896 x∈[-93.757, 47.511] μ=-13.378 σ=14.596\n7: ReLU()\n    Out: tensor[1, 384, 13, 13] n=64896 x∈[0., 47.511] μ=0.887 σ=2.976\n8: Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    Out: tensor[1, 256, 13, 13] n=43264 x∈[-59.236, 44.692] μ=-9.512 σ=9.022\n9: ReLU()\n    Out: tensor[1, 256, 13, 13] n=43264 x∈[0., 44.692] μ=0.583 σ=2.167\n10: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    Out: tensor[1, 256, 13, 13] n=43264 x∈[-43.151, 24.330] μ=-6.892 σ=5.207\n11: ReLU()\n    Out: tensor[1, 256, 13, 13] n=43264 x∈[0., 24.330] μ=0.168 σ=0.939\n12: MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    Out: tensor[1, 256, 6, 6] n=9216 x∈[0., 24.330] μ=0.619 σ=1.803\n\n\n\n\nExplore the first Conv block (Conv-ReLu-MaxPool)\n\npool_idxs = [ i for i in range(len(f)) if isinstance(f[i], nn.MaxPool2d) ]\npool_idxs\n\n[2, 5, 12]\n\n\n\nc1 = f[pool_idxs[0]-2] # Conv  1\nr1 = f[pool_idxs[0]-1] # ReLU  1\nm1 = f[pool_idxs[0]] # MaxPool 1\n\nConvolution input\n\nc1.inp.plt\n\n\n\n\nNote the 3 pillars on the right. It’s the white margins that are part of the image.\nR, G and B channels are normalized with slightly different values, so you see 3 pillars\ninstead of one at max.\n\nsigmas(c1.inp, 2).chans\n\n\n\n\nConvolution output\n\nsigmas(c1.out, n=1).chans(scale=2)\n\n\n\n\nI see a lot of edge detectors, and a bunch of other things.\n\ndef pos_sigmas(x: torch.Tensor, n=2):\n    \"Give n an input of non-negative numbers, rescale it fit nσ into [0..1] range\"\n    return x / (n * (x[ x> 0 ].std()))\n\nReLu output\n\n(pos_sigmas(r1.out, n=2) + 0.5).chans(scale=2)\n\n\n\n\n\n(pos_sigmas(r1.out[0,4,:], n=4) + 0.5).chans(scale=10) # A wide edge detector\n\n\n\n\nAfter MaxPool. Note that a lot fewer pixels are zero / close to zero.\n\n(pos_sigmas(m1.out, n=2) + 0.5).chans(scale=2)\n\n\n\n\n\n\n\nDeconvNet\n\nGet the indices of the values that went through MaxPool\n\n\nidx_max_pool2d = nn.MaxPool2d(kernel_size=3, stride=2, return_indices=True)\n_, m1_switch = idx_max_pool2d(m1.inp) # Returns tuple (maxs, max_idxs)\nm1_switch\n\ntensor[1, 64, 27, 27] n=46656 x∈[0., 3.024e+03] μ=1.499e+03 σ=859.119 i64\n\n\n\ntorch.set_printoptions(linewidth=120)\nm1_switch[0,0,:16,:16].v # Top left corner\n\ntensor[16, 16] n=256 x∈[2.000, 1.792e+03] μ=873.312 σ=510.421 i64\ntensor([[  55,    2,    4,   63,   64,   10,   69,  125,   17,   20,   20,   23,   26,   26,   29,   30],\n        [ 110,  112,  114,  227,  229,  177,  179,  125,  126,  183,  187,  187,  134,  137,  138,  141],\n        [ 220,  222,  224,  227,  229,  287,  287,  290,  237,  293,  242,  242,  244,  246,  248,  307],\n        [ 330,  332,  334,  448,  449,  340,  342,  456,  457,  348,  350,  352,  466,  467,  468,  472],\n        [ 440,  442,  444,  448,  449,  450,  509,  510,  511,  570,  572,  572,  576,  576,  580,  527],\n        [ 550,  552,  554,  668,  668,  671,  672,  675,  678,  624,  572,  572,  576,  576,  635,  635],\n        [ 660,  662,  664,  777,  668,  671,  672,  786,  678,  678,  680,  682,  684,  686,  745,  745],\n        [ 770,  772,  774,  777,  778,  780,  839,  786,  786,  788,  790,  792,  794,  908,  908,  800],\n        [ 880,  882,  884,  998,  998, 1001, 1004,  896,  896,  898,  900,  902,  904,  908,  908, 1020],\n        [ 990,  992,  994,  998,  998, 1001, 1004, 1116, 1116, 1008, 1010, 1012, 1014, 1017, 1073, 1020],\n        [1100, 1102, 1104, 1217, 1163, 1167, 1168, 1226, 1226, 1230, 1230, 1122, 1124, 1127, 1128, 1130],\n        [1210, 1212, 1214, 1217, 1328, 1220, 1224, 1226, 1226, 1230, 1230, 1232, 1290, 1236, 1238, 1352],\n        [1320, 1322, 1324, 1328, 1328, 1387, 1388, 1391, 1391, 1338, 1452, 1452, 1399, 1346, 1348, 1407],\n        [1430, 1432, 1434, 1436, 1438, 1497, 1497, 1444, 1446, 1448, 1507, 1507, 1454, 1456, 1570, 1462],\n        [1540, 1542, 1544, 1603, 1603, 1662, 1662, 1554, 1556, 1670, 1672, 1672, 1676, 1676, 1570, 1627],\n        [1650, 1652, 1654, 1767, 1659, 1662, 1662, 1664, 1666, 1780, 1780, 1672, 1676, 1676, 1678, 1792]])\n\n\n\nunpool_2d = nn.MaxUnpool2d(kernel_size=3, stride=2)\nunpooled_m1_inp = unpool_2d(m1.out, m1_switch)\nunpooled_m1_inp.plt(plt0=0)\n\n\n\n\n\n(pos_sigmas(unpooled_m1_inp, n=2)+0.5).chans\n\n\n\n\n\n(pos_sigmas(unpooled_m1_inp[0,4]) + 0.5).chans(scale=5)\n\n\n\n\n\n(pos_sigmas(m1.inp[0,4]) + 0.5).chans(scale=5)\n\n\n\n\n\n(pos_sigmas(m1.out[0,4]) + 0.5).chans(scale=5)\n\n\n\n\n\n(idx_max_pool2d(unpooled_m1_inp)[0] == m1.out).all().item()\n\nTrue\n\n\nI seems to work. It looks a bit sparse because the Pool kernel=2 and stride=2.\nIf an input pixel has a high activation, it will zero out all pixels in a 5x5 pixel square."
  }
]